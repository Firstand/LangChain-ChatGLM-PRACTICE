import gradio as gr
import config
from knowledge_based_chat_llm import KnowledgeBasedChatLLM

chat_llm = KnowledgeBasedChatLLM()


def init_model():
    chat_llm.init_model_config()


def reinitialize_model(history):
    return history + [[None, "æš‚ä¸æ”¯æŒé‡æ–°åŠ è½½æ¨¡å‹ï¼"]]


def init_vector_store(file_obj, history):
    chat_llm.init_knowledge_vector_store(file_obj.name)
    return history + [[None, "çŸ¥è¯†åº“æ–‡ä»¶å‘é‡åŒ–å®Œæˆï¼"]]


def predict(message, top_k, history_len, temperature, top_p, chat_history):
    resp = chat_llm.get_knowledge_based_answer(
        query=message,
        web_content='',
        top_k=top_k,
        history_len=history_len,
        temperature=temperature,
        top_p=top_p,
        history=chat_history
    )
    chat_history.append((message, resp['result']))
    return "", chat_history


def clear_predict():
    return '', None


if __name__ == '__main__':
    # Large Language Model (LLM) å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å­—å…¸
    llm_model_dict = config.llm_model_dict
    # åµŒå…¥æ¨¡å‹
    embedding_model_dict = config.embedding_model_dict
    # æŒ‡å®šåˆå§‹åŒ–Large Language Model (LLM) å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹
    init_llm = config.init_llm
    # æŒ‡å®šåˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    init_embedding_model = config.init_embedding_model

    # Large Language Model (LLM) å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åˆ—è¡¨
    llm_model_list = []
    for i in llm_model_dict:
        for j in llm_model_dict[i]:
            llm_model_list.append(j)

    # æ ¹æ®é…ç½®åˆå§‹åŒ–æ¨¡å‹
    init_model()

    with gr.Blocks() as demo:
        gr.Markdown("""<h1><center>LangChain-ChatLLM-PRACTICE</center></h1>""")
        # ä¸€è¡Œ
        with gr.Row():
            # å æ•´è¡Œçš„å¤šå°‘
            with gr.Column(scale=1):
                # æŠ˜å åŒº
                with gr.Accordion("æ¨¡å‹é€‰æ‹©"):
                    # Dropdown ä¸‹æ‹‰æ¡†
                    large_language_model = gr.Dropdown(llm_model_list,
                                                       label="Large Language Model (LLM) å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹",
                                                       value=init_llm,
                                                       interactive=True)
                    embedding_model_dict = gr.Dropdown(list(embedding_model_dict.keys()),
                                                       value=init_embedding_model,
                                                       label="Embedding model åµŒå…¥æ¨¡å‹",
                                                       interactive=True)
                    # æŒ‰é’®
                    load_model_button = gr.Button("é‡æ–°åŠ è½½æ¨¡å‹")
                # æŠ˜å åŒº
                with gr.Accordion("æ¨¡å‹å‚æ•°é…ç½®"):
                    # æ»‘å— æœ€å°å€¼ minimum=1, æœ€å¤§å€¼ maximum=10, é»˜è®¤å€¼ value=6, æ»‘åŠ¨ä¸€æ¬¡æ¶¨å‡ ä¸ªæ•° step=1, æ˜¯å¦å¯äº’åŠ¨/ç¼–è¾‘ interactive=True
                    top_k = gr.Slider(minimum=1, maximum=10, value=6, step=1, label="çŸ¢é‡æœç´¢å…³é”®è¯é‡‡æ ·ä¸ªæ•°", interactive=True)
                    history_len = gr.Slider(minimum=0, maximum=5, value=3, step=1, label="å†å²æ¶ˆæ¯ä¸ªæ•°", interactive=True)
                    temperature = gr.Slider(minimum=0, maximum=1, value=0.01, step=0.01, label="æ¸©åº¦å‚æ•°", interactive=True)
                    top_p = gr.Slider(minimum=0, maximum=1, value=0.9, step=0.1, label="æ ¸å¿ƒé‡‡æ ·é˜ˆå€¼", interactive=True)
                # æ–‡ä»¶ä¸Šä¼ 
                file = gr.File(label="è¯·ä¸Šä¼ æœ¬åœ°çŸ¥è¯†åº“", file_types=['.txt', '.md', '.docx', '.pdf'])
                # æŒ‰é’®
                init_vs = gr.Button("çŸ¥è¯†åº“æ–‡ä»¶å‘é‡åŒ–")
                # å•é€‰æ¡†
                use_web = gr.Radio(["æ˜¯", "å¦"], label="ç½‘ç«™æœç´¢", value="å¦", interactive=True)
            # å æ•´è¡Œçš„å¤šå°‘
            with gr.Column(scale=4):
                # èŠå¤©æ¡†
                chat_bot = gr.Chatbot(label='ChatLLM')
                inp = gr.Textbox(placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼", label="æé—®")
                with gr.Row():
                    clear_history = gr.Button("ğŸ§¹ æ¸…é™¤å†å²å¯¹è¯")
                    send = gr.Button("ğŸš€ å‘é€")

        clear_history.click(fn=clear_predict, inputs=[], outputs=[inp, chat_bot])
        inp.submit(fn=predict, inputs=[inp, top_k, history_len, temperature, top_p, chat_bot], outputs=[inp, chat_bot])
        send.click(fn=predict, inputs=[inp, top_k, history_len, temperature, top_p, chat_bot], outputs=[inp, chat_bot])
        load_model_button.click(fn=reinitialize_model, inputs=[chat_bot], outputs=[chat_bot])
        init_vs.click(fn=init_vector_store, show_progress=True, inputs=[file, chat_bot], outputs=[chat_bot])
    demo.launch(inbrowser=True)
